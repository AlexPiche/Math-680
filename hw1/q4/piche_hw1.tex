\documentclass{article}
\usepackage{mathtools}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title{MATH 680 Homework 1 Fall 2015}
\date{\today}
 
\begin{document}
\maketitle

This homework is due on Wednesday, September 16 at 11:59pm. Provide both pdf, R
files (and \LaTeX file for exercise 3). The naming convention is 
yourlastname\_hw1.pdf, yourlastname\_hw1.R and yourlastname\_hw1.lyx \\


\noindent 1. (20\%) Walk through the following steps:
\begin{itemize}
\item Sign up on https://github.com/.
\item Create a repository (repo).
\item Add me as a collaborator (github ID: emeryyi).
\item Download and install SourceTree https://www.sourcetreeapp.com/ or
  alternatively GitHub Desktop https://desktop.github.com/ as the graphical user
  interface (GUI) client. 
\item Clone the repository your created on github.com to your local folder using the GUI client.
\item Add an R file in the local folder, then stage and commit changes.
\item Push the changes to your origin repo on github.com
\item Make a new branch and switch to the new branch using “checkout”.
\item Make some changes in the new branch, then stage and commit.
\item Switch to the master (old) branch using “checkout”.
\item Make some changes in the old branch (but make sure they do not conflict with the changes in the new branch), then stage and commit.
\item Merge the old branch with the new branch, and then commit.• Push all the changes to the remote server.
\item Provide the hyperlink and a screen shot of your github repo in a pdf file, which reflects all the commits, branching and merging you made in your repo.
\end{itemize}


\noindent 2. (80\%) In this exercise, we reproduce the “random function generator” (RFG) model by \cite{friedman2001greedy} (the paper is included, see page 19 section 6.1) in R. The RFG model generates very complicated data with non-linearity and higher-order interactions. The data generated by RFG can be used for 
1 testing the performance of many fully non-parametric regression-based learning methods such as kernel support vector machine (KSVM), gradient boosting, random forests and others.

The idea is to generate a data frame with $N = 100$ observations of simulation data $\{y_i,x_i\}^N_1$ according to

$y_i =f(x_i)+\epsilon_i$,
where $\epsilon_i$s are independent generated from the normal distribution
$\epsilon ∼ N(0, 1)$. In the data frame y takes up the first column, and the $p =
10$ dimensional vector $x$ takes up the rest columns. Hence the data frame will be
$100 \times 11$. Each row represents one observation. The $f$ functions is randomly
generated as a linear combination of functions $\{g_l\}_l^{20}$:

\begin{equation}
f(x) = \sum_{l=1}^{20} a_l g_l (z_l),
\end{equation}

where coefficients $\{a_l\}_1^{20}$ are randomly generated from a uniform
distribution $a_l ∼ U[−1, 1]$. Each $g_l(z_l)$ is a function of a randomly selected
$p_l$-size subset (sub-vector) of the p-dimensional variable $x$, with $p = 10$, and
the size of each subset $p_l$ is randomly chosen by $p_l = min(\floor*{5 + r} ,
p)$, and $r$ 
is generated from an exponential distribution $r \sim \text{Exp}(0.5)$ with mean
2. Each $z_l$ is a sub-vector of x defined as 

\begin{equation}
z_l = \{x_{W_l (j)}\}_{j=1}^{p_l},
\end{equation}

where each $W_l$ is an independent permutation of the integers ${1,\ldots, p}$.
Each function $g_l(z_l)$ is an $p_l$-dimensional Gaussian function:

\begin{equation}
  g_l(z_l) = \exp \Bigg[ -\frac{1}{2} (z_l-\mu_l)^T V_l(z_l-\mu_l) \Bigg],
\end{equation}

where each of the mean vectors ${\mu_l}_1^{20}$ is randomly
generated from the same distribution as that of the input variables $x$. The
$p_l × p_l$ covariance matrix $Vl$ is also randomly generated by

\begin{equation}
V_l = U_lD_lU^T_l ,
\end{equation}

where Ul is a $p_l \times p_l$ uniformly distributed random orthonormal
matrix and $D_l = diag \{d_{1l} \dots dp_{p_l l}\}$. The variables $d_{jl}$ are randomly generated from
a uniform distribution $\sqrt{d_{jl}} \sim U[0.1, 2.0]$. We generated $x$ from joint normal
distribution $x \sim N(0, I_p)$ with $p = 10$.

Hints:
\begin{itemize} 

\item In this exercise, you will
probably use the following R functions:

\begin{itemize} 
\item rexp, runif, rnorm
\item floor
\item qr.Q, qr
\item diag
\item sample
\end{itemize} 
 
\item To generate the uniformly distributed random orthonormal matrix Ul, please see
this post
http://math.stackexchange.com/questions/138512/sampling-q-uniformly-where-qtq-i.
Specifically, you need to generate a Gaussian matrix G, and use QR decomposition
to find the corresponding Q matrix, which will be a uniformly distributed random
orthonormal matrix. Use R functions qr.Q and qr to achieve this. Or much easier,
you can just use the genQ function in the package bootSVD
https://cran.r-project.org/web/packages/bootSVD/ index.html to do the same
job.
\item If it is your first time using R, learn the above functions using their
online manuals before starting the actual coding.
\end{itemize} 



\noindent 3. (Extra credit 40\%) Walk
through the following steps:

\begin{itemize}
\item Download and install LYX. To make LYX work
correctly, Mac users may also need to install MacTEX https://tug.org/mactex/
while the Windows users may need to install MikTEX http://miktex.org/.

\item Reproduce this document using LYX, make sure that all text contents,
mathematical formu- las, references and typesetting (bullet, bold text, url,
title, etc.) are accurately reproduced. However, the layout of the document do
not need to be exactly the same. (paper margin, line space, etc.).
\end{itemize}

\bibliographystyle{plain} 
\bibliography{Untitled} 
\end{document}
